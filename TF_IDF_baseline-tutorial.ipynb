{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import warnings\n",
    "\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long answer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"book\"])\n",
    "n_answers = 1\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(json_data, annotated=False):\n",
    "    # Parse JSON data\n",
    "    candidates = json_data['long_answer_candidates']\n",
    "    doc_tokenized = json_data['document_text'].split(' ')\n",
    "    question = json_data['question_text']\n",
    "    question_s = question.split(' ') \n",
    "    if annotated:\n",
    "        ann = json_data['annotations'][0]\n",
    "\n",
    "    # TFIDF for the document\n",
    "    \n",
    "    #Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words)\n",
    "    tfidf.fit([json_data['document_text']])  # Learn vocabulary and idf from training set.\n",
    "    q_tfidf = tfidf.transform([question]).todense()  #  Transform documents to document-term matrix.\n",
    "\n",
    "    # Find the nearest answer from candidates\n",
    "    scores = []\n",
    "    for i, c in enumerate(candidates):\n",
    "        s, e = c['start_token'], c['end_token']\n",
    "        t = ' '.join(doc_tokenized[s:e])\n",
    "        t_tfidf = tfidf.transform([t]).todense()\n",
    "        score = 1 - spatial.distance.cosine(q_tfidf, t_tfidf)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Put the nearest condidate   \n",
    "        \n",
    "    ans = (np.array(candidates)[np.argsort(scores)])[-n_answers:].tolist()\n",
    "    \n",
    "    \n",
    "    if np.max(scores) < 0.2:\n",
    "        ans_long = ['-1:-1']\n",
    "        ans = [{'start_token': 0, 'end_token': 0}]\n",
    "    else:\n",
    "        ans_long = [str(a['start_token']) + ':' + str(a['end_token']) for a in ans]\n",
    "    \n",
    "        \n",
    "    # Preparing data for debug\n",
    "    if annotated:\n",
    "        ann_long_text = ' '.join(doc_tokenized[ann['long_answer']['start_token']:ann['long_answer']['end_token']])\n",
    "        \n",
    "    else:\n",
    "        ann_long_text = ''\n",
    "        \n",
    "        \n",
    "    ans_long_text = [' '.join(doc_tokenized[a['start_token']:a['end_token']]) for a in ans]\n",
    "                    \n",
    "    return ans_long, question, ann_long_text, ans_long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04df29613d304168bd664ffadd997b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 45s, sys: 20.1 s, total: 4h 1min 5s\n",
      "Wall time: 4h 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ids = []\n",
    "anns = []\n",
    "preds = []\n",
    "\n",
    "# Debug data\n",
    "questions = []\n",
    "ann_texts = []\n",
    "ans_texts = []\n",
    "\n",
    "n_samples = 300_000\n",
    "\n",
    "with open('simplified-nq-train.jsonl', 'r') as json_file:\n",
    "    cnt = 0\n",
    "    for line in tqdm(json_file):\n",
    "        json_data = json.loads(line)\n",
    "\n",
    "        l_ann = str(json_data['annotations'][0]['long_answer']['start_token']) + ':' + \\\n",
    "            str(json_data['annotations'][0]['long_answer']['end_token'])\n",
    "        \n",
    "\n",
    "        l_ans, question, ann_long_text, ans_long_text = predict(json_data, annotated=True)\n",
    "        \n",
    "        ids += [str(json_data['example_id']) + '_long']*len(l_ans)\n",
    "        \n",
    "    \n",
    "        anns += [l_ann]*len(l_ans)\n",
    "       \n",
    "        \n",
    "        preds += l_ans\n",
    "        \n",
    "        questions += [question]*len(l_ans)\n",
    "\n",
    "        ann_texts += [ann_long_text]*len(l_ans)\n",
    "       \n",
    "        ans_texts += ans_long_text\n",
    "        \n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt >= n_samples:\n",
    "            break\n",
    "\n",
    "            \n",
    "train_ann = pd.DataFrame()\n",
    "train_ann['example_id'] = ids\n",
    "train_ann['question'] = questions\n",
    "train_ann['CorrectString'] = anns\n",
    "train_ann['CorrectText'] = ann_texts\n",
    "if len(preds) > 0:\n",
    "    train_ann['PredictionString'] = preds\n",
    "    train_ann['PredictionText'] = ans_texts\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.1012\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(train_ann['CorrectString'].values, train_ann['PredictionString'].values, average='micro')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
