{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2333c50c2f7448d6a42c126a7dae4c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0b7d0f1635f4950987ab25226624686",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88e5683d31a149bcab1e6c45e6f9f940",
              "IPY_MODEL_4817edf69ee04c738916c1b5c2055ccb"
            ]
          }
        },
        "c0b7d0f1635f4950987ab25226624686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88e5683d31a149bcab1e6c45e6f9f940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ea4b4fdf5444fe399cdd43bb0484da7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d4154658fac420fb63de4df13606281"
          }
        },
        "4817edf69ee04c738916c1b5c2055ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6a98af720bb47e7a4f4711826766643",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "9998it [17:33, 16.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baebef7189d2419d8a32b71299464512"
          }
        },
        "5ea4b4fdf5444fe399cdd43bb0484da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d4154658fac420fb63de4df13606281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6a98af720bb47e7a4f4711826766643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baebef7189d2419d8a32b71299464512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80acc1464a8f42e7a317ff7450eafc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34f057725c914729a60c285d5c941e50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e3cc5ceffe34ad68016b5126f954882",
              "IPY_MODEL_77d0c518036f421596115359d484f79b"
            ]
          }
        },
        "34f057725c914729a60c285d5c941e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e3cc5ceffe34ad68016b5126f954882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a3271495499428698ed6fdd9695bb1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_965a9fc81f1b42139dccd914992c27ab"
          }
        },
        "77d0c518036f421596115359d484f79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db6659a38e744256940d33992343d743",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "9999it [50:17,  4.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ff65e632356433fbb95209005c004e1"
          }
        },
        "8a3271495499428698ed6fdd9695bb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "965a9fc81f1b42139dccd914992c27ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db6659a38e744256940d33992343d743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ff65e632356433fbb95209005c004e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralexdmitriy/parallel_hw/blob/master/colab_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdcYLc3lqHrx",
        "colab_type": "text"
      },
      "source": [
        "#### This is tutorial which explains 3 different methods to make the baseline results in Kaggle competition https://www.kaggle.com/c/tensorflow2-question-answering/overview:\n",
        "###1) Using CPU-only method without parallel computing\n",
        "###2) Using multiprocessing\n",
        "###3) Using PyCuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCOb8Tjh04lR",
        "colab_type": "text"
      },
      "source": [
        "#### In this competition, your goal is to predict short and long answer responses to real questions about Wikipedia articles. In this tutorial we try to predict only long answers using TF-IDF similarity between question and condidate to answer based on appropriate article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-l632T42B4m",
        "colab_type": "text"
      },
      "source": [
        "## 1) CPU-only method without parallel computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiCb1b3x3jM6",
        "colab_type": "text"
      },
      "source": [
        "###Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjwgF--92HGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import spatial\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-7QlONo3nZE",
        "colab_type": "text"
      },
      "source": [
        "### Mounting Google Drive to read dataset (150k lines in json: 8Gb) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLzAN1IG4W08",
        "colab_type": "code",
        "outputId": "d003e180-3063-48ff-f3e1-267c750d9904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06QF4MU7BNdl",
        "colab_type": "text"
      },
      "source": [
        "## Data overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PhEjGiNAzgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKdChdK25JV0",
        "colab_type": "code",
        "outputId": "cc898f0c-684f-4bc6-c2a3-6e5423f75251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "path = 'drive/My Drive/Colab Notebooks/150k.json'\n",
        "def read_data(path,  chunksize = 5):\n",
        "   \n",
        "    df = []\n",
        "    with open(path, 'rt') as reader:\n",
        "        for i in range(chunksize):\n",
        "            df.append(json.loads(reader.readline()))\n",
        "    df = pd.DataFrame(df)\n",
        "    return df\n",
        "\n",
        "train = read_data(path)\n",
        "train[['document_text', 'question_text', 'long_answer_candidates', 'annotations']].head(2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_text</th>\n",
              "      <th>question_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "      <th>annotations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Email marketing - Wikipedia &lt;H1&gt; Email marketing &lt;/H1&gt; Jump to : navigation , search &lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This article has multiple issues . Please help improve it or discuss thes...</td>\n",
              "      <td>which is the most common use of opt-in e-mail marketing</td>\n",
              "      <td>[{'start_token': 14, 'top_level': True, 'end_token': 170}, {'start_token': 15, 'top_level': False, 'end_token': 169}, {'start_token': 52, 'top_level': False, 'end_token': 103}, {'start_token': 53,...</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'start_token': 1952, 'candidate_index': 54, 'end_token': 2019}, 'short_answers': [{'start_token': 1960, 'end_token': 1969}], 'annotation_id': 59316545022...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Mother ( How I Met Your Mother ) - wikipedia &lt;H1&gt; The Mother ( How I Met Your Mother ) &lt;/H1&gt; Jump to : navigation , search &lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Tracy McConnell &lt;/Th&gt; &lt;/Tr&gt; &lt;Tr&gt; &lt;Td_co...</td>\n",
              "      <td>how i.met your mother who is the mother</td>\n",
              "      <td>[{'start_token': 28, 'top_level': True, 'end_token': 212}, {'start_token': 29, 'top_level': False, 'end_token': 35}, {'start_token': 35, 'top_level': False, 'end_token': 45}, {'start_token': 45, '...</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'start_token': 212, 'candidate_index': 15, 'end_token': 310}, 'short_answers': [{'start_token': 213, 'end_token': 215}], 'annotation_id': 120348741537837...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                             document_text                                            question_text                                                                                                                                                                                   long_answer_candidates                                                                                                                                                                                              annotations\n",
              "0  Email marketing - Wikipedia <H1> Email marketing </H1> Jump to : navigation , search <Table> <Tr> <Td> </Td> <Td> ( hide ) This article has multiple issues . Please help improve it or discuss thes...  which is the most common use of opt-in e-mail marketing  [{'start_token': 14, 'top_level': True, 'end_token': 170}, {'start_token': 15, 'top_level': False, 'end_token': 169}, {'start_token': 52, 'top_level': False, 'end_token': 103}, {'start_token': 53,...  [{'yes_no_answer': 'NONE', 'long_answer': {'start_token': 1952, 'candidate_index': 54, 'end_token': 2019}, 'short_answers': [{'start_token': 1960, 'end_token': 1969}], 'annotation_id': 59316545022...\n",
              "1  The Mother ( How I Met Your Mother ) - wikipedia <H1> The Mother ( How I Met Your Mother ) </H1> Jump to : navigation , search <Table> <Tr> <Th_colspan=\"2\"> Tracy McConnell </Th> </Tr> <Tr> <Td_co...                  how i.met your mother who is the mother  [{'start_token': 28, 'top_level': True, 'end_token': 212}, {'start_token': 29, 'top_level': False, 'end_token': 35}, {'start_token': 35, 'top_level': False, 'end_token': 45}, {'start_token': 45, '...  [{'yes_no_answer': 'NONE', 'long_answer': {'start_token': 212, 'candidate_index': 15, 'end_token': 310}, 'short_answers': [{'start_token': 213, 'end_token': 215}], 'annotation_id': 120348741537837..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Yi7qsgNB9xb"
      },
      "source": [
        "### Preprocessing and TFIDF - Vectorising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7fJYcnqHryH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = text.ENGLISH_STOP_WORDS.union([\"book\"])\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5EwdhN6B6r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(json_data):\n",
        "    # Parse JSON data\n",
        "    candidates = json_data['long_answer_candidates']\n",
        "    doc_tokenized = json_data['document_text'].split(' ')\n",
        "    question = json_data['question_text']\n",
        "    question_s = question.split(' ') \n",
        "    annotation = json_data['annotations'][0]\n",
        "\n",
        "    # TFIDF for the document\n",
        "    # Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "\n",
        "    tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words)\n",
        "    tfidf.fit([json_data['document_text']])  \n",
        "    q_tfidf = tfidf.transform([question]).todense() \n",
        "    \n",
        "    # Find the nearest answer from candidates using cosine distanse\n",
        "    scores = []\n",
        "    for i, c in enumerate(candidates):\n",
        "        s, e = c['start_token'], c['end_token']\n",
        "        t = ' '.join(doc_tokenized[s:e])\n",
        "        t_tfidf = tfidf.transform([t]).todense()\n",
        "       \n",
        "        score = 1 - spatial.distance.cosine(q_tfidf, t_tfidf)\n",
        "        scores.append(score)\n",
        "\n",
        "    # Put the nearest condidate \n",
        "\n",
        "    ans = (np.array(candidates)[np.argsort(scores)])[-1] # dict, top condidate\n",
        "    \n",
        "    if np.max(scores) < 0.2:\n",
        "        ans_long = '-1:-1'\n",
        "        ans = {'start_token': 0, 'end_token': 0}\n",
        "    else:\n",
        "        ans_long = str(ans['start_token']) + ':' + str(ans['end_token'])\n",
        "              \n",
        "    return ans_long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcyVpT7oHTYE",
        "colab_type": "code",
        "outputId": "78c8baa8-2651-442a-a329-1bbbac3c5598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "2333c50c2f7448d6a42c126a7dae4c1e",
            "c0b7d0f1635f4950987ab25226624686",
            "88e5683d31a149bcab1e6c45e6f9f940",
            "4817edf69ee04c738916c1b5c2055ccb",
            "5ea4b4fdf5444fe399cdd43bb0484da7",
            "4d4154658fac420fb63de4df13606281",
            "b6a98af720bb47e7a4f4711826766643",
            "baebef7189d2419d8a32b71299464512"
          ]
        }
      },
      "source": [
        "%%time\n",
        "ids, annotations, predictions = [], [], []\n",
        "n_samples = 10000\n",
        "with open('drive/My Drive/Colab Notebooks/150k.json', 'r') as json_file:\n",
        "    cnt = 0\n",
        "    for line in tqdm(json_file):\n",
        "        json_data = json.loads(line)\n",
        "\n",
        "        annotated_answer = str(json_data['annotations'][0]['long_answer']['start_token']) + ':' + \\\n",
        "            str(json_data['annotations'][0]['long_answer']['end_token'])\n",
        "        \n",
        "        predicted_answer = predict(json_data)\n",
        "        \n",
        "        ids.append(str(json_data['example_id']) + '_long')\n",
        "        annotations.append(annotated_answer)\n",
        "        predictions.append(predicted_answer)\n",
        "        \n",
        "        cnt += 1\n",
        "        if cnt >= n_samples:\n",
        "            break\n",
        "\n",
        "# Generating Dataframe\n",
        "df = pd.DataFrame()\n",
        "df['example_id'] = ids\n",
        "df['CorrectString'] = annotations\n",
        "df['PredictionString'] = predictions\n",
        "\n",
        "# Evaluating\n",
        "f1 = f1_score(df['CorrectString'].values, df['PredictionString'].values, average='micro')\n",
        "print(f'F1-score: {f1:.4f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2333c50c2f7448d6a42c126a7dae4c1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "F1-score: 0.1013\n",
            "CPU times: user 17min 12s, sys: 6.95 s, total: 17min 19s\n",
            "Wall time: 17min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZNZV0UcfdtP",
        "colab_type": "text"
      },
      "source": [
        "##Using multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6He3m5XsMOqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from multiprocessing import Process, Manager"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODKwu6kf_-vt",
        "colab_type": "code",
        "outputId": "0b9e31f2-5cf4-4860-8c68-4088c737b149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f\" Logical CPU count: {psutil.cpu_count(logical=True)}\")\n",
        "print(f\" Physical CPU count: {psutil.cpu_count(logical=False)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Logical CPU count: 2\n",
            " Physical CPU count: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6TxdhXi2la",
        "colab_type": "text"
      },
      "source": [
        "### Refactoring process function for multiprocessing: split data to chunks which will handle by different processes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHN-7A_oiMuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process(json_path, chunk_index, total_list):\n",
        "    \n",
        "    ids, annotations, predictions = [], [], []\n",
        "    n_rows = 10000\n",
        "    num_cores = 2\n",
        "    chunk_size = int(n_rows/num_cores)  # number of rows for 1 chunk\n",
        "    \n",
        "    with open(json_path, 'r') as json_file:\n",
        "        \n",
        "        cnt = 0 + (chunk_index-1)*chunk_size # starting row\n",
        "        start_row = cnt\n",
        "        finish_row = chunk_size*chunk_index\n",
        "        \n",
        "        for i, line in enumerate(json_file):\n",
        "           \n",
        "            if i < start_row or i > finish_row:\n",
        "              continue\n",
        "            \n",
        "            json_data = json.loads(line)\n",
        "            annotated_answer = str(json_data['annotations'][0]['long_answer']['start_token']) + ':' + \\\n",
        "                str(json_data['annotations'][0]['long_answer']['end_token'])\n",
        "\n",
        "            predicted_answer = predict(json_data)\n",
        "\n",
        "            ids.append(str(json_data['example_id']) + '_long')\n",
        "            annotations.append(annotated_answer)\n",
        "            predictions.append(predicted_answer)\n",
        "\n",
        "            cnt += 1\n",
        "            \n",
        "            if cnt%(chunk_size/10) == 0 and cnt < (chunk_size+1):\n",
        "                print(f\"computing progress: {int(cnt*100/chunk_size)}%\")\n",
        "            \n",
        "            if cnt >= finish_row:\n",
        "                break\n",
        "\n",
        "    chunk_dict = {}\n",
        "    chunk_dict['example_id'] = ids\n",
        "    chunk_dict['CorrectString'] = annotations\n",
        "    chunk_dict['PredictionString'] = predictions\n",
        "    total_list.append(chunk_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxxFS3tqUsAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_list = list()\n",
        "def multiprocessed():\n",
        "    cores = 2\n",
        "    processes = []\n",
        "    a = time.time()\n",
        "    with Manager() as manager:\n",
        "        sum_list = manager.list()  # <-- can be shared between processes.\n",
        "        for i in range(0, cores):\n",
        "            p = Process(target=process,args=(path, i+1, sum_list))\n",
        "            processes.append(p)\n",
        "        # Start the processes\n",
        "        for p in processes:\n",
        "            p.start()\n",
        "        # Ensure all processes have finished execution\n",
        "        for p in processes:\n",
        "            p.join()\n",
        "        \n",
        "        sum_list = list(sum_list)\n",
        "        b = time.time()\n",
        "        print(f\"the executing time using multiprocessing is: {round(b-a, 3)} sec\")\n",
        "        return sum_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV7A5F7ugUUg",
        "colab_type": "code",
        "outputId": "2a95b3fd-92b1-4eb3-ab83-9df5b3a04785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sum_list = multiprocessed()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "computing progress: 10%\n",
            "computing progress: 20%\n",
            "computing progress: 30%\n",
            "computing progress: 40%\n",
            "computing progress: 50%\n",
            "computing progress: 60%\n",
            "computing progress: 70%\n",
            "computing progress: 80%\n",
            "computing progress: 90%\n",
            "computing progress: 100%\n",
            "the executing time using multiprocessing is: 783.324 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xePeiojugZSE",
        "colab_type": "code",
        "outputId": "2a4cde60-18ba-4c8a-853d-8e68ee814922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def creating_df(lst):\n",
        "    total_df = pd.DataFrame()\n",
        "    for l in lst:\n",
        "        df_chunk = pd.DataFrame.from_dict(l)\n",
        "        total_df = total_df.append(df_chunk)\n",
        "    total_df.reset_index(inplace=True, drop=True)\n",
        "    return total_df\n",
        "total_df = creating_df(sum_list)    \n",
        "f1 = f1_score(total_df['CorrectString'].values, total_df['PredictionString'].values, average='micro')\n",
        "print(f'F1-score: {f1:.4f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score: 0.1013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvxcdBmJJX-r",
        "colab_type": "text"
      },
      "source": [
        "### Due to google colab provide only 1 physical CPU for user, multiprocessing reduces computation time only for 24.5%. So try to compute this in local machine (laptop with 4 physical CPU , see multiprocessing_local_machine.ipynb in current repo). Spoiler: computation time reduces by 3.3x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFY80zfwyOc0",
        "colab_type": "text"
      },
      "source": [
        "## 3) Using PyCuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4QmPRdyR4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "70c89b9c-0987-4a63-b40e-588d9327d99c"
      },
      "source": [
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.cumath as cumath\n",
        "import skcuda.linalg as linalg\n",
        "linalg.init()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2019.1.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.3)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.0)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2019.1.1)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.17.5)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.12.0)\n",
            "Requirement already satisfied: scikit-cuda in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (1.17.5)\n",
            "Requirement already satisfied: mako>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (1.1.0)\n",
            "Requirement already satisfied: pycuda>=2016.1 in /usr/local/lib/python3.6/dist-packages (from scikit-cuda) (2019.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako>=1.0.1->scikit-cuda) (1.1.1)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (4.4.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (2019.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda>=2016.1->scikit-cuda) (1.4.3)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda>=2016.1->scikit-cuda) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5SSAV6fzNYt",
        "colab_type": "text"
      },
      "source": [
        "### Refactor the most frequently used function **cosine distanse** with pycuda/skcuda.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXzMhqzozoGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_distance_cuda(u, v):\n",
        "  \"\"\"Computes the cosine distanse between two vectors u and v\"\"\"\n",
        "  \n",
        "  u = spatial.distance._validate_vector(u)\n",
        "  v = spatial.distance._validate_vector(v)\n",
        "  \n",
        "  u = u.astype(np.float32)\n",
        "  v = v.astype(np.float32)\n",
        "  u_gpu = gpuarray.to_gpu(u)\n",
        "  v_gpu = gpuarray.to_gpu(v)\n",
        "  \n",
        "  uv_gpu = gpuarray.dot(u_gpu, v_gpu)\n",
        "  u_gpu_mag = cumath.sqrt(gpuarray.dot(u_gpu, u_gpu))\n",
        "  v_gpu_mag = cumath.sqrt(gpuarray.dot(v_gpu, v_gpu))\n",
        " \n",
        "  dist = 1.0 - uv_gpu / (u_gpu_mag * v_gpu_mag)\n",
        " \n",
        "  return dist.get().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F526t_Q0CUb",
        "colab_type": "text"
      },
      "source": [
        "### Ok, let's replace default scipy **cosine distance** function with **cosine_distance_cuda** in predict function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzooywRh0XvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(json_data):\n",
        "    # Parse JSON data\n",
        "    candidates = json_data['long_answer_candidates']\n",
        "    doc_tokenized = json_data['document_text'].split(' ')\n",
        "    question = json_data['question_text']\n",
        "    question_s = question.split(' ') \n",
        "    annotation = json_data['annotations'][0]\n",
        "\n",
        "    # TFIDF for the document\n",
        "    # Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "\n",
        "    tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words)\n",
        "    tfidf.fit([json_data['document_text']])  \n",
        "    q_tfidf = tfidf.transform([question]).todense() \n",
        "    \n",
        "    # Find the nearest answer from candidates using cosine distanse\n",
        "    scores = []\n",
        "    for i, c in enumerate(candidates):\n",
        "        s, e = c['start_token'], c['end_token']\n",
        "        t = ' '.join(doc_tokenized[s:e])\n",
        "        t_tfidf = tfidf.transform([t]).todense()\n",
        "        \n",
        "        #Replacing below\n",
        "        score = 1 - cosine_distance_cuda(q_tfidf, t_tfidf)\n",
        "        scores.append(score)\n",
        "\n",
        "    # Put the nearest condidate \n",
        "\n",
        "    ans = (np.array(candidates)[np.argsort(scores)])[-1] # dict, top condidate\n",
        "    \n",
        "    if np.max(scores) < 0.2:\n",
        "        ans_long = '-1:-1'\n",
        "        ans = {'start_token': 0, 'end_token': 0}\n",
        "    else:\n",
        "        ans_long = str(ans['start_token']) + ':' + str(ans['end_token'])\n",
        "              \n",
        "    return ans_long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gceXppee08tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "80acc1464a8f42e7a317ff7450eafc0a",
            "34f057725c914729a60c285d5c941e50",
            "8e3cc5ceffe34ad68016b5126f954882",
            "77d0c518036f421596115359d484f79b",
            "8a3271495499428698ed6fdd9695bb1c",
            "965a9fc81f1b42139dccd914992c27ab",
            "db6659a38e744256940d33992343d743",
            "1ff65e632356433fbb95209005c004e1"
          ]
        },
        "outputId": "7c26e899-2ef5-4b33-eacd-a7119edc7882"
      },
      "source": [
        "%%time\n",
        "ids, annotations, predictions = [], [], []\n",
        "n_samples = 10000\n",
        "with open('drive/My Drive/Colab Notebooks/150k.json', 'r') as json_file:\n",
        "    cnt = 0\n",
        "    for line in tqdm(json_file):\n",
        "        json_data = json.loads(line)\n",
        "\n",
        "        annotated_answer = str(json_data['annotations'][0]['long_answer']['start_token']) + ':' + \\\n",
        "            str(json_data['annotations'][0]['long_answer']['end_token'])\n",
        "        \n",
        "        predicted_answer = predict(json_data)\n",
        "        \n",
        "        ids.append(str(json_data['example_id']) + '_long')\n",
        "        annotations.append(annotated_answer)\n",
        "        predictions.append(predicted_answer)\n",
        "        \n",
        "        cnt += 1\n",
        "        if cnt >= n_samples:\n",
        "            break\n",
        "\n",
        "# Generating Dataframe\n",
        "df = pd.DataFrame()\n",
        "df['example_id'] = ids\n",
        "df['CorrectString'] = annotations\n",
        "df['PredictionString'] = predictions\n",
        "\n",
        "# Evaluating\n",
        "f1 = f1_score(df['CorrectString'].values, df['PredictionString'].values, average='micro')\n",
        "print(f'F1-score: {f1:.4f}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80acc1464a8f42e7a317ff7450eafc0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*** compiler output in /tmp/tmpc_u55t85\n",
            "*** compiler output in /tmp/tmpr3zxs5u8\n",
            "F1-score: 0.1009\n",
            "CPU times: user 49min 53s, sys: 21.5 s, total: 50min 15s\n",
            "Wall time: 50min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPhf0TD1BmdO",
        "colab_type": "text"
      },
      "source": [
        "### Text processing with PyCuda increases computation time by 2.94x. What's wrong with it? Let's try to analyse our new cosine distanse function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTcWNLQwCj1w",
        "colab_type": "text"
      },
      "source": [
        "### Scipy cosine distanse function from source:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7xmF962Bi-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_distance(u, v):\n",
        "  \"\"\"Computes the cosine distanse between two vectors u and v in Scipy\"\"\"\n",
        "  u = spatial.distance._validate_vector(u)\n",
        "  v = spatial.distance._validate_vector(v)\n",
        "  uv = np.average(u * v)\n",
        "  uu = np.average(np.square(u))\n",
        "  vv = np.average(np.square(v))\n",
        "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
        "  return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCuJS7tICyfa",
        "colab_type": "text"
      },
      "source": [
        "### Our PyCuda cosine distance funtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf-JIoHXCrmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_distance_cuda(u, v):\n",
        "  \"\"\"Computes the cosine distanse between two vectors u and v\"\"\"\n",
        "  \n",
        "  u = spatial.distance._validate_vector(u)\n",
        "  v = spatial.distance._validate_vector(v)\n",
        "  \n",
        "  u = u.astype(np.float32)\n",
        "  v = v.astype(np.float32)\n",
        "  u_gpu = gpuarray.to_gpu(u)\n",
        "  v_gpu = gpuarray.to_gpu(v)\n",
        "  \n",
        "  uv_gpu = gpuarray.dot(u_gpu, v_gpu)\n",
        "  u_gpu_mag = cumath.sqrt(gpuarray.dot(u_gpu, u_gpu))\n",
        "  v_gpu_mag = cumath.sqrt(gpuarray.dot(v_gpu, v_gpu))\n",
        " \n",
        "  dist = 1.0 - uv_gpu / (u_gpu_mag * v_gpu_mag)\n",
        " \n",
        "  return dist.get().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEsDmV7ODRnM",
        "colab_type": "text"
      },
      "source": [
        "### Computing time depends on input vectors dimension. Let's compare two functions productivity depending on vectors dimension from 1x1 to 1x1e9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb6xraXCD5uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_dims = [1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8]\n",
        "vector_dims = [int(x) for x in vector_dims]\n",
        "freq_vector_dims = []\n",
        "for i, v in enumerate(vector_dims):\n",
        "  if i < len(vector_dims) -1:\n",
        "    l = [x for x in range(v, vector_dims[i+1], 2*v )]\n",
        "    freq_vector_dims += l\n",
        "  else:\n",
        "    freq_vector_dims.append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdujckwyD-a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_cosine(iter_num, dim, CUDA=False):\n",
        "  start = time.time()\n",
        "  for i in range(iter_num):\n",
        "      u =  np.random.rand(1,dim).squeeze()\n",
        "      v =  np.random.rand(1,dim).squeeze()\n",
        "      if CUDA:\n",
        "        d = cosine_distance_cuda(u, v)\n",
        "      else:  \n",
        "        d = cosine_distance(u, v)\n",
        "  finish = time.time()\n",
        "  proc_time = finish - start\n",
        "  return proc_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z45FkVCDECso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_logs_cpu = []\n",
        "time_logs_cuda = []\n",
        "for dim in freq_vector_dims:\n",
        "  proc_cpu = test_cosine(5, dim)\n",
        "  proc_cuda = test_cosine(5, dim, CUDA=True)\n",
        "  time_logs_cpu.append(proc_cpu)\n",
        "  time_logs_cuda.append(proc_cuda)\n",
        "time_logs_cpu = [x/5 for x in time_logs_cpu]\n",
        "time_logs_cuda = [x/5 for x in time_logs_cuda]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9HtbtYKE-S7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2de5e510-4df9-4a3a-9560-366d131e9244"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=freq_vector_dims, y=time_logs_cpu,\n",
        "                    mode='lines+markers',\n",
        "                    name='CPU time'))\n",
        "fig.add_trace(go.Scatter(x=freq_vector_dims, y=time_logs_cuda,\n",
        "                    mode='lines+markers',\n",
        "                    name='CUDA time'))\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': \"Comparing of cosine distanсe function computation time\",\n",
        "        'xanchor': 'center',\n",
        "        'y':0.9,\n",
        "        'x':0.5,\n",
        "        'yanchor': 'top'},\n",
        "    xaxis_title=\"Input vectors 1D dimension\",\n",
        "    yaxis_title=\"Execution time, sec\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=16,\n",
        "        color=\"#7f7f7f\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"38388ac9-fdc2-460a-b236-b7785005c314\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"38388ac9-fdc2-460a-b236-b7785005c314\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '38388ac9-fdc2-460a-b236-b7785005c314',\n",
              "                        [{\"mode\": \"lines+markers\", \"name\": \"CPU time\", \"type\": \"scatter\", \"x\": [1, 3, 5, 7, 9, 10, 30, 50, 70, 90, 100, 300, 500, 700, 900, 1000, 3000, 5000, 7000, 9000, 10000, 30000, 50000, 70000, 90000, 100000, 300000, 500000, 700000, 900000, 1000000, 3000000, 5000000, 7000000, 9000000, 10000000, 30000000, 50000000, 70000000, 90000000, 100000000], \"y\": [0.00028543472290039064, 6.766319274902344e-05, 0.00011043548583984375, 5.168914794921875e-05, 9.717941284179688e-05, 5.1021575927734375e-05, 6.761550903320313e-05, 4.744529724121094e-05, 4.773139953613281e-05, 4.7540664672851564e-05, 5.311965942382813e-05, 5.526542663574219e-05, 5.7697296142578125e-05, 6.613731384277343e-05, 8.592605590820312e-05, 8.392333984375e-05, 0.00014171600341796874, 0.00018124580383300782, 0.0001998424530029297, 0.00027256011962890626, 0.0003034114837646484, 0.0006561756134033203, 0.0013346672058105469, 0.002363777160644531, 0.0026053428649902345, 0.003271198272705078, 0.007663869857788086, 0.011720418930053711, 0.016598844528198244, 0.02055044174194336, 0.022575998306274415, 0.07670917510986328, 0.1364152431488037, 0.20096979141235352, 0.2628058910369873, 0.28647680282592775, 0.8303768634796143, 1.3686019897460937, 1.909783411026001, 2.467861461639404, 2.7055598735809325]}, {\"mode\": \"lines+markers\", \"name\": \"CUDA time\", \"type\": \"scatter\", \"x\": [1, 3, 5, 7, 9, 10, 30, 50, 70, 90, 100, 300, 500, 700, 900, 1000, 3000, 5000, 7000, 9000, 10000, 30000, 50000, 70000, 90000, 100000, 300000, 500000, 700000, 900000, 1000000, 3000000, 5000000, 7000000, 9000000, 10000000, 30000000, 50000000, 70000000, 90000000, 100000000], \"y\": [0.002291297912597656, 0.0014559268951416016, 0.0016326904296875, 0.0015353679656982422, 0.0013233184814453124, 0.001044321060180664, 0.0009976863861083985, 0.0009864330291748046, 0.00096893310546875, 0.0010098457336425782, 0.001031208038330078, 0.0009655952453613281, 0.0009710311889648438, 0.0011414527893066407, 0.0010501861572265625, 0.001230764389038086, 0.0013998031616210937, 0.0014681816101074219, 0.001724576950073242, 0.001431894302368164, 0.001525115966796875, 0.0018232345581054687, 0.0022964954376220705, 0.0028872966766357424, 0.0040166378021240234, 0.0038006782531738283, 0.008247661590576171, 0.011838865280151368, 0.01595273017883301, 0.02007780075073242, 0.023178672790527342, 0.06748971939086915, 0.11440682411193848, 0.16541695594787598, 0.21319751739501952, 0.23202757835388182, 0.6835158824920654, 1.1182714462280274, 1.5594513893127442, 2.009912395477295, 2.2197885036468508]}],\n",
              "                        {\"font\": {\"color\": \"#7f7f7f\", \"family\": \"Courier New, monospace\", \"size\": 16}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Comparing of cosine distan\\u0441e function computation time\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.9, \"yanchor\": \"top\"}, \"xaxis\": {\"title\": {\"text\": \"Input vectors 1D dimension\"}}, \"yaxis\": {\"title\": {\"text\": \"Execution time, sec\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('38388ac9-fdc2-460a-b236-b7785005c314');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrJ20V4DFFWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "fa83818c-2353-4e51-b114-6935650c7148"
      },
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=freq_vector_dims[10:29], y=time_logs_cpu[10:29],\n",
        "                    mode='lines+markers',\n",
        "                    name='CPU time'))\n",
        "fig.add_trace(go.Scatter(x=freq_vector_dims[10:29], y=time_logs_cuda[10:29],\n",
        "                    mode='lines+markers',\n",
        "                    name='CUDA time'))\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': \"Comparing of cosine distanсe function computation time (zoomed)\",\n",
        "        'xanchor': 'center',\n",
        "        'y':0.9,\n",
        "        'x':0.5,\n",
        "        'yanchor': 'top'},\n",
        "    xaxis_title=\"Input vectors 1D dimension\",\n",
        "    yaxis_title=\"Execution time, sec\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=16,\n",
        "        color=\"#7f7f7f\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"17a91b0f-4d92-4a4d-aa05-533d22607348\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"17a91b0f-4d92-4a4d-aa05-533d22607348\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '17a91b0f-4d92-4a4d-aa05-533d22607348',\n",
              "                        [{\"mode\": \"lines+markers\", \"name\": \"CPU time\", \"type\": \"scatter\", \"x\": [100, 300, 500, 700, 900, 1000, 3000, 5000, 7000, 9000, 10000, 30000, 50000, 70000, 90000, 100000, 300000, 500000, 700000], \"y\": [5.311965942382813e-05, 5.526542663574219e-05, 5.7697296142578125e-05, 6.613731384277343e-05, 8.592605590820312e-05, 8.392333984375e-05, 0.00014171600341796874, 0.00018124580383300782, 0.0001998424530029297, 0.00027256011962890626, 0.0003034114837646484, 0.0006561756134033203, 0.0013346672058105469, 0.002363777160644531, 0.0026053428649902345, 0.003271198272705078, 0.007663869857788086, 0.011720418930053711, 0.016598844528198244]}, {\"mode\": \"lines+markers\", \"name\": \"CUDA time\", \"type\": \"scatter\", \"x\": [100, 300, 500, 700, 900, 1000, 3000, 5000, 7000, 9000, 10000, 30000, 50000, 70000, 90000, 100000, 300000, 500000, 700000], \"y\": [0.001031208038330078, 0.0009655952453613281, 0.0009710311889648438, 0.0011414527893066407, 0.0010501861572265625, 0.001230764389038086, 0.0013998031616210937, 0.0014681816101074219, 0.001724576950073242, 0.001431894302368164, 0.001525115966796875, 0.0018232345581054687, 0.0022964954376220705, 0.0028872966766357424, 0.0040166378021240234, 0.0038006782531738283, 0.008247661590576171, 0.011838865280151368, 0.01595273017883301]}],\n",
              "                        {\"font\": {\"color\": \"#7f7f7f\", \"family\": \"Courier New, monospace\", \"size\": 16}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Comparing of cosine distan\\u0441e function computation time (zoomed)\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.9, \"yanchor\": \"top\"}, \"xaxis\": {\"title\": {\"text\": \"Input vectors 1D dimension\"}}, \"yaxis\": {\"title\": {\"text\": \"Execution time, sec\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('17a91b0f-4d92-4a4d-aa05-533d22607348');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWwOkbUPOKTM",
        "colab_type": "text"
      },
      "source": [
        "### As you can see from plots, CUDA cosine function become faster than default function beginning only from 1x500k vectors dimension. In our task the input vectors dimension is about 1000 and this function is executed about 70 times in every question. Therefore, our CUDA function makes text processing slower. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVAoYnC0Q6sM",
        "colab_type": "text"
      },
      "source": [
        "### In this tutorial we try to use 3 methods to compute TF-IDF similarity for solving Kaggle competiotion task. The most appropriate method is multiprocessing, while the PyCuda method was the slowest one because of small input vectors dimensions and expensive transformation from numpy array to gpu array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9j2NTE4ToHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}